{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "owuMk_guREX5",
    "outputId": "ba7cd846-f092-473b-e412-32461a6d779b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 15:44:34.352436: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-22 15:44:34.352467: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from scripts.load_data import load_train, load_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_lLaBNewZk0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Het importeren en bewerken van de data \n",
    "train_images, train_labels = load_train(padding=((0, 0), (0, 0), (0, 0)))\n",
    "test_images, test_labels = load_test(padding=((0, 0), (0, 0), (0, 0)))\n",
    "\n",
    "# Normalizeren van de images\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshapen van de images zodat ze de juiste dimensies hebben\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFleZ8yEyFtk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 15:44:37.590092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-22 15:44:37.590124: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-22 15:44:37.590147: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (delta): /proc/driver/nvidia/version does not exist\n",
      "2022-02-22 15:44:37.590424: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Onze CNN\n",
    "\n",
    "# Stap 1: bepaal hoeveel filters je wilt, hoe groot je filter size moet zijn (let op je filter size mag niet te groot zijn vergeleken met je images), en wat je pool size is. \n",
    "num_filters = 3\n",
    "filter_size = 3\n",
    "pool_size = 4\n",
    "\n",
    "# Stap 2: maak het model.\n",
    "#    In de array die je aan sequential meegeeft, zet je alle layers die in het model moeten:\n",
    "#    Conv2D, parameters: num_filters, filter_size, input_shape=(x, y, z)\n",
    "#    MaxPooling2D, parameters: pool_size=pool_size\n",
    "#    Flatten,\n",
    "#    Dense, parameters: aantal outputs, activation='softmax'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=num_filters, kernel_size=filter_size, input_shape=train_images.shape[1:]))\n",
    "model.add(Conv2D(filters=num_filters, kernel_size=filter_size, input_shape=train_images.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "he8Zs-Sd2TID"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 15:44:38.118744: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12/1875 [..............................] - ETA: 28s - loss: 2.3011 - accuracy: 0.1328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 15:44:39.102087: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28180224 exceeds 10% of free system memory.\n",
      "2022-02-22 15:44:39.102245: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28180224 exceeds 10% of free system memory.\n",
      "2022-02-22 15:44:39.124734: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28180224 exceeds 10% of free system memory.\n",
      "2022-02-22 15:44:39.124907: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28180224 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 32s 16ms/step - loss: 0.7874 - accuracy: 0.7179\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1955 - accuracy: 0.9399\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1622 - accuracy: 0.9501\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f3c45f3cdc0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stap 3: het compilen van het model.\n",
    "# model.compile parameters: 'adam', loss='categorial_crossentropy', metrics=['accuracy']\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Stap 4: fit het model.\n",
    "#    Data om op te trainen: train_images, to_categorial(train_labels)\n",
    "#    epochs = 3\n",
    "#    validation_data = test_images, to_categorial(test_labels)\n",
    "model.fit(train_images, to_categorical(train_labels), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.1356 - accuracy: 0.9576 - 2s/epoch - 7ms/step\n",
      "0.9575999975204468\n"
     ]
    }
   ],
   "source": [
    "# Stap 5: evalueer het model\n",
    "test_loss, test_acc = model.evaluate(test_images, to_categorical(test_labels), verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS8vERMeHh8j"
   },
   "outputs": [],
   "source": [
    "# Stap 6: extra layer(s). Wat gebeurt er als je een extra Conv Layer toevoegd aan je model? \n",
    "#    Voeg een extra layer(s) toe en train het model opnieuw.\n",
    "\n",
    "\n",
    "# Stap 7: parameters. Wat gebeurt er bijvoorbeeld als je geen softmax gebruikt maar een andere activatie? \n",
    "#    Pas op z'n minst 1 parameter aan en train je model opnieuw.\n",
    "\n",
    "# Een extra conv layer lijkt niet zo veel te doen maar een Dense relu layer maakt ~5 procent meer accurate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAd6ElEQVR4nO2daazc53XenzPrXcnLnZeLSUpWFciLZIVQZFtWJCsOFMOFrKIV7A+GPhhRUMRAjaYfBKWo3aIfnLS2YyStAzpWoxSul8QWzLRua0UIICR2ZVEbtVC2NlLc13t591lPP8ywoNT3OffyLnMZv88PIDj3PfP+/2femTP/mfeZc465O4QQv/wUVtsBIURvULALkQkKdiEyQcEuRCYo2IXIBAW7EJlQWspkM7sbwNcAFAH8mbt/Kbr/mrUjvmnzKLFyCdAs/Z5UKBid48H7WCQ2GvgxjUzkM+Y5m0X+L+qIMCqlBucKDhgKs/EDv/KTrQDLfbbY/cWdjc2KT5W2nj9zApMTY8lnZtHBbmZFAP8JwMcAHAPwlJntd/eX2ZxNm0fxpT96OGlrt9v0XP3VanK80tdH57SL6TkA0HT+RlBCkdqKrfR4mbsevjq8xP1osHcWxC+CQotYvUznNBv8iK0CedDAooI9+l1H+JuP4FztduA/mRi+mQZ+RK/TVitYq+h8ZLwZrlXaj3/3L++jc5byMf4WAK+5+xvuXgfwHQD3LOF4QogVZCnBvh3A0cv+PtYdE0Jchaz4Bp2ZPWBmB8zswMTFsZU+nRCCsJRgPw5g52V/7+iOvQ133+fue91975q165ZwOiHEUlhKsD8F4Doz22NmFQCfArB/edwSQiw3i96Nd/emmX0OwP9GR3p72N1fmm9em+yqlqp8t7jeTu9yTl+cpHPKg3z7tljupzY4n9cmO7vNYOe8NdegtrmLs9RW6eNqQgt8R3hqdio5XjB+vKHBtdTmwbnawe6zEVlxsbvgwRKHu/HsOYs2/qMd98jHaDeerQcAtMmqtBepCjCWpLO7+48A/GgpxxBC9Ab9gk6ITFCwC5EJCnYhMkHBLkQmKNiFyIQl7cZfKa12CxPTaWmo0eAS1bmz55Pjx46foXOKfYPUNjTMf9xTLXCJiqly9Sb3vd1oUtvMZHotAKC/zP1Agcsuk/W0HFmvc+nnmj3XUdu7r91Fbf1RIhKRhkLJKEh28cDYjnQ5lhe02IScRRJJbwXy2NqB7LkYdGUXIhMU7EJkgoJdiExQsAuRCQp2ITKhp7vxU9PT+Mn/+Smx8Z3pAtJJMrM1vms610rv4ANAucJtxTZ//2uRDdU55zvurWCneLDCd7P7jT81fVVeOqtVqCfHp6e5YnDg4LPUdubcCWq7Zs8eatu4cWNyvH9ggM7xqLxUkGTSJiWaAMDY89nrWnhRcg1LGlpEIkw0R1d2ITJBwS5EJijYhcgEBbsQmaBgFyITFOxCZEJvE2FabYxPpeuueVD7zUg2Q6nC69YNBNJVscBtFVSobQ5p+acZvGdOzkxT2+w0t1WNy2tDzpNkiuShlau87t7c1By1vX70/ysY/P84cvIUtY2sSde127ljB52zaeMGfrx1PHmpVAi6+BBZbrHJLqzhDsDr3c13PtbdJa5Bd+X+68ouRCYo2IXIBAW7EJmgYBciExTsQmSCgl2ITFiS9GZmhwFMAmgBaLr73uj+bXfM1tMyQ7kcuUKyglo8k8vBbVYM2vQEika9kZaoGoHrwwND1DY5MUNtE3XeGqoWZFBVKmnpcLjCH1ixyOXG6WaNzwsyBGvnLibHx8d5duPgEJcHR0e3Udu1e66htqFKWqasknUC4nqIjaAsnINLgFFmHpPlInWQSYBRrb7l0NnvdPdzy3AcIcQKoo/xQmTCUoPdAfzYzJ42sweWwyEhxMqw1I/xt7n7cTPbDOAxM3vF3Z+4/A7dN4EHAKBvcM0STyeEWCxLurK7+/Hu/2cAPArglsR99rn7XnffW+kL+qILIVaURQe7mQ2a2fCl2wB+E8CLy+WYEGJ5WcrH+C0AHu22tSkB+G/u/r+iCW13zNbS8lWtwd93WOucvqD9UJQTFCTYha2EmG06KJbZ189PVi0HhSMbfN5cjctyTSNZXsHjqgRZY/HlgB+zVEofM/Jjcoav48VXD1HbufNcDBruS2ff7djOs+/WBRl2lSB7MOpf1W7yoqRNospF2ZQtT8vHKyK9ufsbAG5c7HwhRG+R9CZEJijYhcgEBbsQmaBgFyITFOxCZEJPC066O+ok+8daPCuI9bVqFwINLaIaFAYs8ve/diEtn5SCVWwE2WuVEpcOh/p5VtZMnReIbCLtY9AWD7UmN1aD4pzFIMvLyXWk0Q4kKFLQEwAKBf68nLpwhtpO1NJ9/V478hads2lTuk8dAGzbtpPahoaGqa2vGsjERPpseCC9kd53raAQpa7sQmSCgl2ITFCwC5EJCnYhMkHBLkQm9HY3HkAzqMXFaJEd3LmpSTqnFGyRt4JN/FKhTm0sgaZcjpIPgiUOaslFxfCGgrZXTfL2HZSLQyPwo9ni61EwflAn2R2tYMe9VYyKrnFTVKvNLL1WzaCY3MSJMWo7cvIwtVUrfMd9YGCA2lhCV1Qnr1xOP656jdc11JVdiExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmdDzRJhaIy3lsDpzANAmP+5nbXMAoBnUaZsN5IlyIGsVidRULfE5TmrCAYB50C4okMO8zXUolgcx0+IJKHXwcxWC+nT14DkrE53SC/xcjQJ/XJG8VigGNfQsnTQU5NWE9QvbgYZZn+U19CamA+2QyZs1fjwWL7MzE3SOruxCZIKCXYhMULALkQkKdiEyQcEuRCYo2IXIhHmlNzN7GMAnAJxx9/d2x9YD+C6A3QAOA7jP3XmqUJd2u42ZubQUUoq0kDZxM5CnZqdPU1ulwsWV9Vt4W6B+op4UAlmrGNSS80KD2i6OpWunAcDsFJdXdu25Pjk+2Rikc8bGLlJbtcqztRpERgUAI2lq7UhD48sYzmsFh6wgvcaFYlALL2i91YrSB6MswNo0tbXHjybHzx9/g5+L1KdrBPLfQq7sfw7g7neMPQjgcXe/DsDj3b+FEFcx8wZ7t9/6hXcM3wPgke7tRwB8cnndEkIsN4v9zr7F3U92b59Cp6OrEOIqZskbdN75zSr91mRmD5jZATM70KrXlno6IcQiWWywnzazUQDo/k+r9Lv7Pnff6+57i5XqIk8nhFgqiw32/QDu796+H8APl8cdIcRKsRDp7dsA7gCw0cyOAfgCgC8B+J6ZfRbAEQD3LeRkDkerSSSPQD5ZV+1Pjq8Z5LLQ7EDw0IxLRuUpni3XR6o5bt68mc6Z6+dFCOtNLr319/HHVhxIrwcADKxZkxwfGRylc7Zu5F+vouy7uUAOmyHzTp3lkmhjepzays7XqtTk7bCK7fRz3WgExUqLfO3b4M9nO2iVhVl+vokTh5PjtTG+VlNT6eesSQp9AgsIdnf/NDHdNd9cIcTVg35BJ0QmKNiFyAQFuxCZoGAXIhMU7EJkQk8LTsIdaKalkLUDw3TaCJHRjp98i86ZDX7AUwuy1OzUEWrbsyEtsW3euZ3OeeXECWrzNs+uGpjmEuDaQS7/vHD0+eT40FaedTVU5QUz3/zFy9TWGlxHbSPXvT99rm3vpnOmjxyitmKQ6bfGeabXzNR4enyS/g4MlfIQtU3M8eKW/SObqG1DP3+up0hmHoKehMayRIMCp7qyC5EJCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhN6Lr0VWmmZYesQlztOj6VlksYw1yZKw1zKKxiXT5oNXjdz183vSY6PBb3S6uuC7DXjy19Yw+W18QmeQTU5l5bs2jPjdE5tjkuRawM/jk5xyWv6bLpg5q6RETpn2/VpuQ4Axl/mmW3Tx7lcOnY6bZuY5gU9WyS7EQAuzvLXXP86Lr0N7+S2JunPNjfLsxFZDz4L9Dpd2YXIBAW7EJmgYBciExTsQmSCgl2ITOjpbnypWMT6Neld8o1DfPd8/EK6Ftf6Pp7AUS3zXclmg+8+b7423T4JAK4Z3Zkcf+kt3qZnpMrbPzWD9kmbt45QW2EjVy6mS+n378Iw92Ps7Clq27WZt8OaqXD/x1rpxJsLY2fpnMLou6htxw23UtvxY69Q29zsTHK8XOSvDw/6SRXbvBZebZwn15wFV1CaM2kfC0V+LW6RVmQRurILkQkKdiEyQcEuRCYo2IXIBAW7EJmgYBciExbS/ulhAJ8AcMbd39sd+yKA3wZwSUd5yN1/NN+xKuUidm1dn7T9k9/6KJ135I3dyfHJOZ6IUZvjslCzxqW33du4/OPttCTjG7fSORcDeW16hvu/YyNvKdV0nngzNZ1OGPE+XpNvyHktuWKbazxb1vI2VNNn0hLb1PG0zAQAjRp/XINbuAS47T0fobZ242Jy/MyJ1+mcmSkukyFYjzWDPMGqBF5T0EkUNmb4uZwkvHjQkmshV/Y/B3B3Yvyr7n5T99+8gS6EWF3mDXZ3fwLAhR74IoRYQZbynf1zZnbQzB42M/45UAhxVbDYYP86gGsB3ATgJIAvszua2QNmdsDMDtRIYQUhxMqzqGB399Pu3nL3NoBvALgluO8+d9/r7nurfXxDRwixsiwq2M1s9LI/7wXw4vK4I4RYKRYivX0bwB0ANprZMQBfAHCHmd0EwAEcBvA7CzlZ0Rxrimlp6IM3c8nrlvek2ytNzvAaXQ3n72ONJpcnmjP8q8bsXPp8e+q8/dNMjcsnU0GLp3KZPzVjE7wVUt+edHbbbI2vlY9spLbjp05S26tv8vZbN6xLS4dvnQ32ettcumr18azIoV03U9tHrt2dHL9wlEtvP3/maWo7c+rn1DZovH4harz91lyL1JNrcymyVE7PqZMaj8ACgt3dP50Y/uZ884QQVxf6BZ0QmaBgFyITFOxCZIKCXYhMULALkQk9LTjZbjYxdSEtTxx7k0v1O7bvSY5vH91C55QGuFTTDtouTZw7R23j42nfN6zfQOdMz3IpZGY2yIib4lLN5NRaarv+2mvSx5sOpJ9ZLgFu6ufZcuUaf2y/+msfSo5fmOFzDp9KZ6gBQL3A21C1ZnlrKJCWTNven35NAcCm93+M2ppj6eKnAHDh0JPU9uaLT1Hbudd/kRwvVPhzViilZTkLiqnqyi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhM6Kn0ViwUMdI/mLRNnuf9xk6S7J+NW3m/rrVF/tAGh0eoDWu5ZFe0tGw0HKTprw162HlhcX3gDr3Me5tt2pSWmgYGeFbhTCDz3bibZ/T9+l6ebTZLMgtnuDKE63byDMHT57k8eOIUz6Q79ebR5PhbQT+3uUC27R/hhS9H3psq1djhpus/SG3b3zyYHD/4E17a8eypN5Pjbrygp67sQmSCgl2ITFCwC5EJCnYhMkHBLkQm9HQ3vlwsYnR9OonD6jxB4sLpM8nx5w++Ruc8+yKvFbZl+05q+8iv305t2zelfZ8b4zugxVKwVR/sxpdK/Kl51zZepr+/r5wcr1b4+/qaygC1YZj72GhxPyZJAtBsiysoh149TG1jtXQ7KQC4+Zq0AgEAU5vT6/jmSa7+HDrC1Y7n3+CvucnqCLVtXMPX+IYtacVj7+08IefZnz6WHD/yWpA8Qy1CiF8qFOxCZIKCXYhMULALkQkKdiEyQcEuRCaYO08IAAAz2wngLwBsQafd0z53/5qZrQfwXQC70WkBdZ+7B/1vgHXDQ37H3vclbe97V7pdEACs3ZCWVp5+iUskrwQyzofvvIvamuDr8Y/vui05vq6Pz+nr50kVpTKXY2bnuJy3aQNfq4FqOtGoHrR/irBi0EYruFZYOV0z7tUjx+icP/wPX6W2c2d4ssuv3Zp+XgDgE//sM8lxr/G6dS8+9TNqO9Hk0uFL47xdU7vIa/n57Hhy/LogJo6/+kxy/CeP78fFC+eSTi7kyt4E8HvufgOAWwH8rpndAOBBAI+7+3UAHu/+LYS4Spk32N39pLs/0709CeAQgO0A7gHwSPdujwD45Ar5KIRYBq7oO7uZ7QbwAQBPAtji7pdafJ5C52O+EOIqZcHBbmZDAL4P4PPu/raewd754p/84mpmD5jZATM7UGvwn8QKIVaWBQW7mZXRCfRvufsPusOnzWy0ax8FkPwBu7vvc/e97r63Wk7/blsIsfLMG+xmZuj0Yz/k7l+5zLQfwP3d2/cD+OHyuyeEWC4WkvX2YQCfAfCCmT3XHXsIwJcAfM/MPgvgCID75jtQo9XG2fG0pPRKmWc1Fc+cT46/dfJkchwAbr/rDmp76F//PrX98Z/8Z2r7H3+9Pzn+K9t5+6dypUhtg8NrqK3V4vXY1q9dT22b1qe3TqIsukqFZ7YVglZZUy1eUK5eSl9Hvv6n/4XOefmVF6itWuY+Prr/L6ltx/VE6r3uH9E5/VXeamqN88e8bYia0CTrAQDTJBPQ61wu3bU9XVPwQLBO8wa7u/8dACYucsFaCHFVoV/QCZEJCnYhMkHBLkQmKNiFyAQFuxCZ0NOCk5VqFdt3vztpa2GSzms00hlKlUGudYzu5G2L3HiW2s5tvL3P3/zw+8nxyVO88OJAP892qvYHxSipAAJUS/zHSUMD6TUZ6OcZdpVArumrcB+9jz+2s7Pp5/OlQy/TOb/xG1zcufGmG6ntG3/G5byfPvE/k+PXbB2hcyoDXC49d4oXqnz+1V9QW3mQr+OWNWlfWrNcfu0nBUT5q0ZXdiGyQcEuRCYo2IXIBAW7EJmgYBciExTsQmRCT6U3h6OJtJzQanM5rFJNy0aDPGkME1O8YOPpMzzD7twFXjPz2Kl09p03eVGOviqXXBoNLq1EZUCrZf60DVbTslyxxOWk/j6e5dXXxyW7dpELPW+dPZ02OJ/zyXvvpbYPfehD1Hb0KC9i+ej+v06OP/v8LjqnNVentrHTF6mtfv44tZVavPDoTHMqOf7G2FE6Z6CalktrtVk6R1d2ITJBwS5EJijYhcgEBbsQmaBgFyITerob32y2cG48vaPdaPJ2PKVC+j3Jm3w3+9mDL1Lb+2781WAer4PG2h3VS3zHvd7gu+AnT56jtrmgPVElqCdXJqeLEiTKFZ5YUw52/lvO2x1NzaV3hddv5O0FNm7gtfwmJyaobevoVmq7MJZWXn784x/ROXNT09R2/nx65xwApo1fO0tBQlSRKBTrtqTbngHA5i3px9wMahfqyi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhMmFd6M7OdAP4CnZbMDmCfu3/NzL4I4LcBXNI2HnJ3rmegU/utZWm5xoq8DtrUTDqpZXaKyyCnzqYlPgD4oz/+E2o78toR7kc9LWu8dpwn1niQ4BO1eGq0uKxlLd4WqEjevy0Q3yyodebG2x1Fch48/bj7B7nv58/z56watKiauMhluVot7f/hwzx5xgJJt8GfFniQNBQlNrEagINVXmNxZjrtYzt4vS1EZ28C+D13f8bMhgE8bWaPdW1fdff/uIBjCCFWmYX0ejsJ4GT39qSZHQLAS7cKIa5Krug7u5ntBvABAE92hz5nZgfN7GEz4/WUhRCrzoKD3cyGAHwfwOfdfQLA1wFcC+AmdK78XybzHjCzA2Z2oFnnRR6EECvLgoLdzMroBPq33P0HAODup9295e5tAN8AcEtqrrvvc/e97r63FPwGWwixsswb7GZmAL4J4JC7f+Wy8dHL7nYvAJ55IoRYdRayG/9hAJ8B8IKZPdcdewjAp83sJnRUhcMAfmfek5VKWL9hPbHy7LBZkoVUC9o/FYIMpPGxcWrbsGkzta1dn85CagZyR9t5PbNmg8tQrSaXvKLade1G2pdI5qvVuI9tIqEBAIKstwK5jowH2Wt//5O/p7Y777yT2l56+RC1sYddD56zYvBabAevq0gubdWCr7D1tC9Hj/AadMVquqZdI/iqvJDd+L9DWlINNXUhxNWFfkEnRCYo2IXIBAW7EJmgYBciExTsQmSCeSStLDNr16/12+66LWlrB9lEpGMUioGYUAqKMlr0kIOMJ5ZRVChyqaZZ522o2i0uebUCGacdLBZ7OpsNLuVNTfPswVqNy4ONRuA/WcfoeAP9vHDn7j17qO3A089Q2/hEunBnlAUYxUQrsAWdrQALcwSTFAr8ddU3kM6wm5saR6vVTJ5MV3YhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkQk97vRkMZmk5oVzm7ztWJLJFi8sZ5XKQOx8lcgUSSZVJbMGcSrDChj5qi6SyVqRTEmkokgc3bGSZiEAj8MODrDcmHbbbXNqcnuYy5anTp6lt924uy01Op7PAZmbTveg68BdIM5TlAkk0eM7Yc1MgPQ47tvRr7szcJJ9DLUKIXyoU7EJkgoJdiExQsAuRCQp2ITJBwS5EJvRUenMY3NMyg7eDXmQkQylKJIoyw0JZrsQlKiMnLESOBMcrBtJKOSiI2GjwooK0sGTgYtSPrmh8rZotLssxpa8cPOb+4RFq2/4u3ust6m82S/rzRZJi9NqxIvc/ypaLjlkkixUXCU1nD168cI7O0ZVdiExQsAuRCQp2ITJBwS5EJijYhciEeXfjzawPwBMAqt37/5W7f8HM9gD4DoANAJ4G8Bn3oNcROru+9bn0DiPb6QYAtgEa7eyGu59Rfbpg99xJgkQ7SJywoF1QIdjpLvdzmxf5bnw12C3mLK4eWzNqUVVPvxTaQbJIdLyZepR0w3et55rptYpeb2CJVwA8OFeU7FKpcDUhqpfIGCA16MLkmQUctwbgo+5+Izrtme82s1sB/AGAr7r7uwGMAfjsFforhOgh8wa7d7hUfrTc/ecAPgrgr7rjjwD45Eo4KIRYHhban73Y7eB6BsBjAF4HMO7ulz53HQOwfUU8FEIsCwsKdndvuftNAHYAuAXAryz0BGb2gJkdMLMD7HucEGLluaLdHHcfB/C3AD4IYMTMLu0s7ABwnMzZ5+573X1vOdikEEKsLPMGu5ltMrOR7u1+AB8DcAidoP+n3bvdD+CHK+SjEGIZWMie/yiAR6xTPK4A4Hvu/t/N7GUA3zGzfw/gWQDfXMgJnfbI4XIHayUE4zJItVqltjiRhNvKlbQcFsl8JXAJrRUkYzSjOnlRwgWRAVnNMiCWoSxK1qkGST7l9Ke46FyRhBatcYPIawBQaKfXuB2cqxnYikGPp3YgHUbP2WJasHGJjfs3b7C7+0EAH0iMv4HO93chxD8A9As6ITJBwS5EJijYhcgEBbsQmaBgFyITbDHb/os+mdlZAEe6f24EwAtm9Q758Xbkx9v5h+bHLnfflDL0NNjfdmKzA+6+d1VOLj/kR4Z+6GO8EJmgYBciE1Yz2Pet4rkvR368Hfnxdn5p/Fi17+xCiN6ij/FCZMKqBLuZ3W1mPzez18zswdXwoevHYTN7wcyeM7MDPTzvw2Z2xsxevGxsvZk9Zmavdv9ft0p+fNHMjnfX5Dkz+3gP/NhpZn9rZi+b2Utm9i+64z1dk8CPnq6JmfWZ2c/M7PmuH/+2O77HzJ7sxs13zezKCkS4e0//ASiiU9bqGgAVAM8DuKHXfnR9OQxg4yqc93YANwN48bKxPwTwYPf2gwD+YJX8+CKAf9Xj9RgFcHP39jCAXwC4oddrEvjR0zVBJ091qHu7DOBJALcC+B6AT3XH/xTAP7+S467Glf0WAK+5+xveKT39HQD3rIIfq4a7PwHgwjuG70GncCfQowKexI+e4+4n3f2Z7u1JdIqjbEeP1yTwo6d4h2Uv8roawb4dwNHL/l7NYpUO4Mdm9rSZPbBKPlxii7uf7N4+BWDLKvryOTM72P2Yv+JfJy7HzHajUz/hSazimrzDD6DHa7ISRV5z36C7zd1vBvBbAH7XzG5fbYeAzjs7EHSeWFm+DuBadHoEnATw5V6d2MyGAHwfwOfdfeJyWy/XJOFHz9fEl1DklbEawX4cwM7L/qbFKlcadz/e/f8MgEexupV3TpvZKAB0/z+zGk64++nuC60N4Bvo0ZqYWRmdAPuWu/+gO9zzNUn5sVpr0j33OK6wyCtjNYL9KQDXdXcWKwA+BWB/r50ws0EzG750G8BvAngxnrWi7EencCewigU8LwVXl3vRgzWxTmG6bwI45O5fuczU0zVhfvR6TVasyGuvdhjfsdv4cXR2Ol8H8Pur5MM16CgBzwN4qZd+APg2Oh8HG+h89/osOj3zHgfwKoC/AbB+lfz4rwBeAHAQnWAb7YEft6HzEf0ggOe6/z7e6zUJ/OjpmgB4PzpFXA+i88byby57zf4MwGsA/hJA9UqOq1/QCZEJuW/QCZENCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkgoJdiEz4vw67s5AWpdmFAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data inladen\n",
    "(train_images10, train_labels10), (test_images10, test_labels10) = cifar10.load_data()\n",
    "\n",
    "plt.imshow(train_images10[4])\n",
    "plt.show()\n",
    "\n",
    "# Normalizeren\n",
    "train_images10, test_images10 = train_images10 / 255.0, test_images10 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 8: bouw je eigen CNN voor de CIFAR-10 dataset. \n",
    "# Tip: gebruik meerdere Conv2D en MaxPooling layers\n",
    "# LET OP: gebruik 'softmax' alleen bij je laatste Dense layer. Gebruik 'relu' voor de andere Conv2D/Dense layers.\n",
    "num_filters = 32\n",
    "filter_size = 3\n",
    "pool_size = 4\n",
    "\n",
    "model_cif = Sequential()\n",
    "model_cif.add(Conv2D(filters=num_filters, kernel_initializer='he_uniform', padding='same', kernel_size=filter_size, input_shape=train_images10.shape[1:], activation=\"relu\"))\n",
    "model_cif.add(Conv2D(filters=num_filters, kernel_initializer='he_uniform', padding='same', kernel_size=filter_size, input_shape=train_images10.shape[1:], activation=\"relu\"))\n",
    "model_cif.add(MaxPooling2D((2,2)))\n",
    "model_cif.add(Conv2D(filters=num_filters*2, kernel_initializer='he_uniform', padding='same', kernel_size=filter_size, input_shape=train_images10.shape[1:], activation=\"relu\"))\n",
    "model_cif.add(Conv2D(filters=num_filters*2, kernel_initializer='he_uniform', padding='same', kernel_size=filter_size, input_shape=train_images10.shape[1:], activation=\"relu\"))\n",
    "model_cif.add(MaxPooling2D((2,2)))\n",
    "model_cif.add(Conv2D(filters=num_filters*2*2, kernel_initializer='he_uniform', padding='same', kernel_size=filter_size, input_shape=train_images10.shape[1:], activation=\"relu\"))\n",
    "model_cif.add(Conv2D(filters=num_filters*2*2, kernel_initializer='he_uniform', padding='same', kernel_size=filter_size, input_shape=train_images10.shape[1:], activation=\"relu\"))\n",
    "model_cif.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model_cif.add(Flatten())\n",
    "model_cif.add(Dense(128, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "model_cif.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_cif.compile(\n",
    "    'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1019/1563 [==================>...........] - ETA: 42s - loss: 1.5228 - accuracy: 0.4441"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel_cif\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_images10\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_labels10\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m#hint: meer dan 3,\u001B[39;49;00m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtest_images10\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_labels10\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/keras/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2953\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2954\u001B[0m   (graph_function,\n\u001B[1;32m   2955\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2956\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1849\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1851\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1852\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1853\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1854\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1855\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1856\u001B[0m     args,\n\u001B[1;32m   1857\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1858\u001B[0m     executing_eagerly)\n\u001B[1;32m   1859\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/repos/Vision/exercises/KHF/python/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_cif.fit(\n",
    "    train_images10,\n",
    "    to_categorical(train_labels10),\n",
    "    epochs=10,  #hint: meer dan 3,\n",
    "    validation_data=(test_images10, to_categorical(test_labels10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_cif.evaluate(test_images10, to_categorical(test_labels10), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronnen\n",
    "* https://victorzhou.com/blog/keras-cnn-tutorial/ Bezocht: 9/3/2020\n",
    "* https://www.tensorflow.org/tutorials/images/cnn Bezocht: 13/3/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}